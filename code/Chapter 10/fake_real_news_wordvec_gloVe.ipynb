{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9f_Ov2F_G5W",
    "outputId": "12d796f7-f3d2-45d0-d56f-4a1bef9a6504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Activation, Flatten\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "\n",
    "# Use English stemmer.\n",
    "word_stemmer = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "zBPa7eAj4F-D",
    "outputId": "3656983c-4f56-45da-b1fb-cf6fd339bffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.1.5\n",
      "  Downloading Keras-2.1.5-py2.py3-none-any.whl (334 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |█                               | 10 kB 32.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 20 kB 34.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 30 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 40 kB 41.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 51 kB 41.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 61 kB 43.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 71 kB 40.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 81 kB 36.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 92 kB 38.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 102 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 112 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 122 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 133 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 143 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 153 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 163 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 174 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 184 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 194 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 204 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 215 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 225 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 235 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 245 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 256 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 266 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 276 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 286 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 296 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 307 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 317 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 327 kB 39.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 334 kB 39.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.19.5)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.1.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "keras"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install keras==2.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGlYLI1NsWao",
    "outputId": "375eb62e-fa36-4931-fdef-729df1301465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "7FgrkZ0K_0jw",
    "outputId": "345f9eaa-6d1c-464f-e853-7b567a1e08b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000-1.csv      california_housing_test.csv   mnist_test.csv         \u001b[0m\u001b[01;32mREADME.md\u001b[0m*\n",
      "\u001b[01;32manscombe.json\u001b[0m*  california_housing_train.csv  mnist_train_small.csv\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xfo4Qofn_G5c"
   },
   "outputs": [],
   "source": [
    "real_news_df = pd.read_csv('sample_data/8000-1.csv')\n",
    "fake_news_df = pd.read_csv('sample_data/fake_news_dataset_csv.csv', encoding= 'unicode_escape').dropna()\n",
    "#real_news_df = real_news_df.rename(columns={\"headline\": \"Article\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4j2mwKxs_G5g",
    "outputId": "caf72ae1-ead9-494b-eda4-340a1c775366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8799, 6)\n",
      "(8810, 6)\n"
     ]
    }
   ],
   "source": [
    "real_news_df['real_fact'] = 1\n",
    "fake_news_df['real_fact'] = 0\n",
    "print(real_news_df.shape)\n",
    "print(fake_news_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtAXZs2G_G5k"
   },
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFVwDWE3_G5l"
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "  # specific\n",
    "  phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "  phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "  # general\n",
    "  phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "  phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "  phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "  phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "  phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "  phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "  return phrase\n",
    "\n",
    "\n",
    "\n",
    "def get_cleaned_data(input_data, mode='df'):\n",
    "  stop = stopwords.words('english')\n",
    "  \n",
    "  input_df = ''\n",
    "  \n",
    "  if mode != 'df':\n",
    "      input_df = pd.DataFrame([input_data], columns=['Article'])\n",
    "  else:\n",
    "      input_df = input_data\n",
    "      \n",
    "  #lowercase the text\n",
    "  input_df['Article'] = input_df['Article'].str.lower()\n",
    "  \n",
    "  input_df['Article'] = input_df['Article'].apply(lambda elem: decontracted(elem))\n",
    "  \n",
    "  #remove special characters\n",
    "  input_df['Article'] = input_df['Article'].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))\n",
    "  \n",
    "  # remove numbers\n",
    "  input_df['Article'] = input_df['Article'].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "  \n",
    "  #remove stopwords\n",
    "  input_df['Article'] = input_df['Article'].apply(lambda x: ' '.join([word.strip() for word in x.split() if word not in (stop)]))\n",
    "  \n",
    "  #stemming, changes the word to root form\n",
    "#     input_df['text'] = input_df['text'].apply(lambda words: [word_stemmer.stem(word) for word in words])\n",
    "  \n",
    "  #lemmatization, same as stemmer, but language corpus is used to fetch the root form, so resulting words make sense\n",
    "#     more description @ https://www.datacamp.com/community/tutorials/stemming-lemmatization-python\n",
    "  input_df['Article'] = input_df['Article'].apply(lambda words: (wordnet_lemmatizer.lemmatize(words)))\n",
    "#     print(input_df.head(3))\n",
    "  \n",
    "  return input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "194DgDMm_G5o",
    "outputId": "c748f302-3236-4d4d-e4ec-6fda33a64dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "(17609, 9)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "fake_news_df = get_cleaned_data(fake_news_df)\n",
    "real_news_df = get_cleaned_data(real_news_df)\n",
    "news_data_df = pd.concat([real_news_df, fake_news_df], ignore_index = True)\n",
    "print(news_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9I2ehPNWZ-CY",
    "outputId": "2743b070-f5af-4dd7-a0b7-e6ba5c9ca9b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Article</th>\n",
       "      <th>Page_url</th>\n",
       "      <th>Source</th>\n",
       "      <th>real_fact</th>\n",
       "      <th>Country</th>\n",
       "      <th>News Type</th>\n",
       "      <th>Fact-Checked by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-04-05 23:59:42+00:00</td>\n",
       "      <td>british prime minister boris johnson hospitali...</td>\n",
       "      <td>https://www.complex.com/life/2020/04/boris-joh...</td>\n",
       "      <td>http://www.complex.com/</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-05 23:59:36+00:00</td>\n",
       "      <td>nsw coronavirus death toll hits cases rise</td>\n",
       "      <td>https://www.sbs.com.au/news/nsw-coronavirus-de...</td>\n",
       "      <td>http://www.sbs.com.au/</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-04-05 23:59:32+00:00</td>\n",
       "      <td>industry chandigarh need major impetus governm...</td>\n",
       "      <td>https://www.hindustantimes.com/chandigarh/indu...</td>\n",
       "      <td>http://www.hindustantimes.com/</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-04-05 23:59:32+00:00</td>\n",
       "      <td>coronavirus chandigarh follow advisories one c...</td>\n",
       "      <td>https://www.hindustantimes.com/chandigarh/coro...</td>\n",
       "      <td>http://www.hindustantimes.com/</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-04-05 23:59:32+00:00</td>\n",
       "      <td>crackers sound jarring note chandigarh tricity...</td>\n",
       "      <td>https://www.hindustantimes.com/chandigarh/crac...</td>\n",
       "      <td>http://www.hindustantimes.com/</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17604</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>coronavirus created lab patented</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>France, United States</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>AFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17605</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>chinese market caused new coronavirus video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Middle East, North Africa</td>\n",
       "      <td>Misleading</td>\n",
       "      <td>Misbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1/19/2020</td>\n",
       "      <td>peak new coronavirus happen two weeks jan two ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Partly FALSE</td>\n",
       "      <td>Animal Político</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17607</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1/18/2020</td>\n",
       "      <td>stores supermarkets veracruz mexico close due ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Animal Político</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1/14/2020</td>\n",
       "      <td>chain message circulated tuesday jan warning p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Rappler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17609 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                       Date  ...     News Type   Fact-Checked by\n",
       "0             1.0  2020-04-05 23:59:42+00:00  ...           NaN               NaN\n",
       "1             2.0  2020-04-05 23:59:36+00:00  ...           NaN               NaN\n",
       "2             3.0  2020-04-05 23:59:32+00:00  ...           NaN               NaN\n",
       "3             4.0  2020-04-05 23:59:32+00:00  ...           NaN               NaN\n",
       "4             5.0  2020-04-05 23:59:32+00:00  ...           NaN               NaN\n",
       "...           ...                        ...  ...           ...               ...\n",
       "17604         NaN                  1/21/2020  ...         FALSE               AFP\n",
       "17605         NaN                  1/21/2020  ...    Misleading            Misbar\n",
       "17606         NaN                  1/19/2020  ...  Partly FALSE   Animal Político\n",
       "17607         NaN                  1/18/2020  ...         FALSE   Animal Político\n",
       "17608         NaN                  1/14/2020  ...         FALSE           Rappler\n",
       "\n",
       "[17609 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5DMhhaz_G5v"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "MAX_NUM_WORDS = 10000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(news_data_df.Article,news_data_df.real_fact,random_state = 42, test_size=VALIDATION_SPLIT, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu0LrqQD_G5y"
   },
   "source": [
    "# Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Necp3Sum_G5z",
    "outputId": "c94bcddb-bc01-4837-d600-0be8ca77943b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16951 unique tokens. and 14087 lines \n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Transforms each text in texts to a sequence of integers. \n",
    "# So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.\n",
    "# sequences = tokenizer.texts_to_sequences(news_data_df.text)\n",
    "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
    "X_train = pad_sequences(tokenized_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens. and {} lines '.format(len(word_index), len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AS5oLhaJSeQY",
    "outputId": "c32dbfcd-de9e-4f3d-84d0-fe7eb24eacbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coronavirus': 1,\n",
       " 'covid': 2,\n",
       " 'people': 3,\n",
       " 'new': 4,\n",
       " 'lockdown': 5,\n",
       " 'video': 6,\n",
       " 'india': 7,\n",
       " 'pandemic': 8,\n",
       " 'cases': 9,\n",
       " 'says': 10,\n",
       " 'shows': 11,\n",
       " 'times': 12,\n",
       " 'virus': 13,\n",
       " 'health': 14,\n",
       " 'hospital': 15,\n",
       " 'china': 16,\n",
       " 'government': 17,\n",
       " 'us': 18,\n",
       " 'due': 19,\n",
       " 'positive': 20,\n",
       " 'news': 21,\n",
       " 'facebook': 22,\n",
       " 'claims': 23,\n",
       " 'patients': 24,\n",
       " 'home': 25,\n",
       " 'president': 26,\n",
       " 'outbreak': 27,\n",
       " 'novel': 28,\n",
       " 'vaccine': 29,\n",
       " 'deaths': 30,\n",
       " 'masks': 31,\n",
       " 'amid': 32,\n",
       " 'trump': 33,\n",
       " 'claim': 34,\n",
       " 'police': 35,\n",
       " 'minister': 36,\n",
       " 'infected': 37,\n",
       " 'man': 38,\n",
       " 'shared': 39,\n",
       " 'social': 40,\n",
       " 'death': 41,\n",
       " 'quarantine': 42,\n",
       " 'cure': 43,\n",
       " 'state': 44,\n",
       " 'pm': 45,\n",
       " 'chinese': 46,\n",
       " 'crisis': 47,\n",
       " 'spread': 48,\n",
       " 'photo': 49,\n",
       " 'italy': 50,\n",
       " 'tests': 51,\n",
       " 'posts': 52,\n",
       " 'said': 53,\n",
       " 'died': 54,\n",
       " 'city': 55,\n",
       " 'fight': 56,\n",
       " 'first': 57,\n",
       " 'doctor': 58,\n",
       " 'medical': 59,\n",
       " 'image': 60,\n",
       " 'one': 61,\n",
       " 'two': 62,\n",
       " 'indian': 63,\n",
       " 'help': 64,\n",
       " 'workers': 65,\n",
       " 'post': 66,\n",
       " 'water': 67,\n",
       " 'wuhan': 68,\n",
       " 'uk': 69,\n",
       " 'face': 70,\n",
       " 'bill': 71,\n",
       " 'world': 72,\n",
       " 'thousands': 73,\n",
       " 'may': 74,\n",
       " 'states': 75,\n",
       " 'country': 76,\n",
       " 'test': 77,\n",
       " 'days': 78,\n",
       " 'gates': 79,\n",
       " 'get': 80,\n",
       " 'april': 81,\n",
       " 'media': 82,\n",
       " 'spain': 83,\n",
       " 'doctors': 84,\n",
       " 'food': 85,\n",
       " 'show': 86,\n",
       " 'multiple': 87,\n",
       " 'g': 88,\n",
       " 'italian': 89,\n",
       " 'twitter': 90,\n",
       " 'testing': 91,\n",
       " 'prime': 92,\n",
       " 'dies': 93,\n",
       " 'prevent': 94,\n",
       " 'whatsapp': 95,\n",
       " 'public': 96,\n",
       " 'could': 97,\n",
       " 'number': 98,\n",
       " 'message': 99,\n",
       " 'toll': 100,\n",
       " 'mask': 101,\n",
       " 'dr': 102,\n",
       " 'million': 103,\n",
       " 'day': 104,\n",
       " 'johnson': 105,\n",
       " 'use': 106,\n",
       " 'would': 107,\n",
       " 'ministry': 108,\n",
       " 'case': 109,\n",
       " 'measures': 110,\n",
       " 'distancing': 111,\n",
       " 'woman': 112,\n",
       " 'found': 113,\n",
       " 'reports': 114,\n",
       " 'brazilian': 115,\n",
       " 'free': 116,\n",
       " 'kill': 117,\n",
       " 'delhi': 118,\n",
       " 'week': 119,\n",
       " 'rules': 120,\n",
       " 'york': 121,\n",
       " 'patient': 122,\n",
       " 'need': 123,\n",
       " 'infection': 124,\n",
       " 'air': 125,\n",
       " 'disease': 126,\n",
       " 'tested': 127,\n",
       " 'time': 128,\n",
       " 'showing': 129,\n",
       " 'claiming': 130,\n",
       " 'used': 131,\n",
       " 'take': 132,\n",
       " 'governor': 133,\n",
       " 'queen': 134,\n",
       " 'brazil': 135,\n",
       " 'boris': 136,\n",
       " 'order': 137,\n",
       " 'hours': 138,\n",
       " 'spanish': 139,\n",
       " 'live': 140,\n",
       " 'stay': 141,\n",
       " 'viral': 142,\n",
       " 'going': 143,\n",
       " 'modi': 144,\n",
       " 'drinking': 145,\n",
       " 'symptoms': 146,\n",
       " 'hospitals': 147,\n",
       " 'party': 148,\n",
       " 'back': 149,\n",
       " 'family': 150,\n",
       " 'every': 151,\n",
       " 'chief': 152,\n",
       " 'without': 153,\n",
       " 'picture': 154,\n",
       " 'call': 155,\n",
       " 'dead': 156,\n",
       " 'former': 157,\n",
       " 'confirmed': 158,\n",
       " 'national': 159,\n",
       " 'treatment': 160,\n",
       " 'money': 161,\n",
       " 'years': 162,\n",
       " 'countries': 163,\n",
       " 'united': 164,\n",
       " 'citizens': 165,\n",
       " 'according': 166,\n",
       " 'online': 167,\n",
       " 'caused': 168,\n",
       " 'go': 169,\n",
       " 'claimed': 170,\n",
       " 'created': 171,\n",
       " 'warns': 172,\n",
       " 'sunday': 173,\n",
       " 'work': 174,\n",
       " 'relief': 175,\n",
       " 'flu': 176,\n",
       " 'french': 177,\n",
       " 'american': 178,\n",
       " 'wearing': 179,\n",
       " 'person': 180,\n",
       " 'report': 181,\n",
       " 'three': 182,\n",
       " 'isolation': 183,\n",
       " 'made': 184,\n",
       " 'streets': 185,\n",
       " 'total': 186,\n",
       " 'allegedly': 187,\n",
       " 'pay': 188,\n",
       " 'south': 189,\n",
       " 'staff': 190,\n",
       " 'emergency': 191,\n",
       " 'govt': 192,\n",
       " 'admitted': 193,\n",
       " 'donald': 194,\n",
       " 'make': 195,\n",
       " 'house': 196,\n",
       " 'march': 197,\n",
       " 'alongside': 198,\n",
       " 'hydroxychloroquine': 199,\n",
       " 'mumbai': 200,\n",
       " 'since': 201,\n",
       " 'france': 202,\n",
       " 'care': 203,\n",
       " 'drug': 204,\n",
       " 'rate': 205,\n",
       " 'risk': 206,\n",
       " 'hot': 207,\n",
       " 'say': 208,\n",
       " 'response': 209,\n",
       " 'bodies': 210,\n",
       " 'market': 211,\n",
       " 'announced': 212,\n",
       " 'reported': 213,\n",
       " 'medicine': 214,\n",
       " 'muslims': 215,\n",
       " 'company': 216,\n",
       " 'using': 217,\n",
       " 'cures': 218,\n",
       " 'die': 219,\n",
       " 'like': 220,\n",
       " 'australia': 221,\n",
       " 'plan': 222,\n",
       " 'rs': 223,\n",
       " 'oil': 224,\n",
       " 'sri': 225,\n",
       " 'calls': 226,\n",
       " 'philippines': 227,\n",
       " 'street': 228,\n",
       " 'top': 229,\n",
       " 'vaccines': 230,\n",
       " 'killed': 231,\n",
       " 'wear': 232,\n",
       " 'despite': 233,\n",
       " 'hundreds': 234,\n",
       " 'arrested': 235,\n",
       " 'study': 236,\n",
       " 'rise': 237,\n",
       " 'urges': 238,\n",
       " 'scientists': 239,\n",
       " 'official': 240,\n",
       " 'year': 241,\n",
       " 'victims': 242,\n",
       " 'children': 243,\n",
       " 'second': 244,\n",
       " 'body': 245,\n",
       " 'keep': 246,\n",
       " 'group': 247,\n",
       " 'control': 248,\n",
       " 'next': 249,\n",
       " 'league': 250,\n",
       " 'away': 251,\n",
       " 'human': 252,\n",
       " 'set': 253,\n",
       " 'many': 254,\n",
       " 'corona': 255,\n",
       " 'military': 256,\n",
       " 'return': 257,\n",
       " 'secretary': 258,\n",
       " 'empty': 259,\n",
       " 'population': 260,\n",
       " 'update': 261,\n",
       " 'daily': 262,\n",
       " 'protect': 263,\n",
       " 'support': 264,\n",
       " 'treat': 265,\n",
       " 'predicted': 266,\n",
       " 'viewed': 267,\n",
       " 'students': 268,\n",
       " 'spreading': 269,\n",
       " 'fund': 270,\n",
       " 'muslim': 271,\n",
       " 'lab': 272,\n",
       " 'avoid': 273,\n",
       " 'last': 274,\n",
       " 'rises': 275,\n",
       " 'epidemic': 276,\n",
       " 'saying': 277,\n",
       " 'global': 278,\n",
       " 'pradesh': 279,\n",
       " 'aid': 280,\n",
       " 'tea': 281,\n",
       " 'general': 282,\n",
       " 'kills': 283,\n",
       " 'lemon': 284,\n",
       " 'virtual': 285,\n",
       " 'called': 286,\n",
       " 'dont': 287,\n",
       " 'africa': 288,\n",
       " 'light': 289,\n",
       " 'also': 290,\n",
       " 'madrid': 291,\n",
       " 'migrant': 292,\n",
       " 'residents': 293,\n",
       " 'photos': 294,\n",
       " 'ventilators': 295,\n",
       " 'five': 296,\n",
       " 'taken': 297,\n",
       " 'open': 298,\n",
       " 'tiger': 299,\n",
       " 'curfew': 300,\n",
       " 'life': 301,\n",
       " 'chloroquine': 302,\n",
       " 'services': 303,\n",
       " 'still': 304,\n",
       " 'economic': 305,\n",
       " 'causes': 306,\n",
       " 'article': 307,\n",
       " 'reveals': 308,\n",
       " 'infections': 309,\n",
       " 'give': 310,\n",
       " 'quarantined': 311,\n",
       " 'text': 312,\n",
       " 'watch': 313,\n",
       " 'holding': 314,\n",
       " 'shares': 315,\n",
       " 'buy': 316,\n",
       " 'members': 317,\n",
       " 'tablighi': 318,\n",
       " 'fauci': 319,\n",
       " 'restrictions': 320,\n",
       " 'officer': 321,\n",
       " 'army': 322,\n",
       " 'sarscov': 323,\n",
       " 'inside': 324,\n",
       " 'close': 325,\n",
       " 'high': 326,\n",
       " 'four': 327,\n",
       " 'closed': 328,\n",
       " 'released': 329,\n",
       " 'community': 330,\n",
       " 'russia': 331,\n",
       " 'salt': 332,\n",
       " 'players': 333,\n",
       " 'authorities': 334,\n",
       " 'mexico': 335,\n",
       " 'hold': 336,\n",
       " 'palm': 337,\n",
       " 'jamaat': 338,\n",
       " 'stock': 339,\n",
       " 'japanese': 340,\n",
       " 'stop': 341,\n",
       " 'breaking': 342,\n",
       " 'per': 343,\n",
       " 'alcohol': 344,\n",
       " 'fake': 345,\n",
       " 'weeks': 346,\n",
       " 'mass': 347,\n",
       " 'force': 348,\n",
       " 'lives': 349,\n",
       " 'university': 350,\n",
       " 'tv': 351,\n",
       " 'sex': 352,\n",
       " 'officials': 353,\n",
       " 'issued': 354,\n",
       " 'effective': 355,\n",
       " 'japan': 356,\n",
       " 'linked': 357,\n",
       " 'british': 358,\n",
       " 'nhs': 359,\n",
       " 'paulo': 360,\n",
       " 'hospitalized': 361,\n",
       " 'offering': 362,\n",
       " 'breath': 363,\n",
       " 'elizabeth': 364,\n",
       " 'already': 365,\n",
       " 'published': 366,\n",
       " 'federal': 367,\n",
       " 'current': 368,\n",
       " 'list': 369,\n",
       " 'homes': 370,\n",
       " 'situation': 371,\n",
       " 'developed': 372,\n",
       " 'zoo': 373,\n",
       " 'protective': 374,\n",
       " 'laboratory': 375,\n",
       " 'dangerous': 376,\n",
       " 'taking': 377,\n",
       " 'biden': 378,\n",
       " 'address': 379,\n",
       " 'travel': 380,\n",
       " 'baby': 381,\n",
       " 'star': 382,\n",
       " 'see': 383,\n",
       " 'funds': 384,\n",
       " 'cause': 385,\n",
       " 'church': 386,\n",
       " 'eating': 387,\n",
       " 'white': 388,\n",
       " 'among': 389,\n",
       " 'nurse': 390,\n",
       " 'put': 391,\n",
       " 'maharashtra': 392,\n",
       " 'gets': 393,\n",
       " 'leader': 394,\n",
       " 'together': 395,\n",
       " 'yearold': 396,\n",
       " 'best': 397,\n",
       " 'giving': 398,\n",
       " 'large': 399,\n",
       " 'event': 400,\n",
       " 'latest': 401,\n",
       " 'north': 402,\n",
       " 'data': 403,\n",
       " 'app': 404,\n",
       " 'pope': 405,\n",
       " 'team': 406,\n",
       " 'alleged': 407,\n",
       " 'cm': 408,\n",
       " 'economy': 409,\n",
       " 'audio': 410,\n",
       " 'fans': 411,\n",
       " 'working': 412,\n",
       " 'centre': 413,\n",
       " 'service': 414,\n",
       " 'youtube': 415,\n",
       " 'around': 416,\n",
       " 'hit': 417,\n",
       " 'princess': 418,\n",
       " 'lost': 419,\n",
       " 'real': 420,\n",
       " 'ecuador': 421,\n",
       " 'employees': 422,\n",
       " 'americans': 423,\n",
       " 'wants': 424,\n",
       " 'de': 425,\n",
       " 'violating': 426,\n",
       " 'gujarat': 427,\n",
       " 'discovered': 428,\n",
       " 'bank': 429,\n",
       " 'khan': 430,\n",
       " 'nurses': 431,\n",
       " 'cured': 432,\n",
       " 'prevents': 433,\n",
       " 'battle': 434,\n",
       " 'today': 435,\n",
       " 'nigeria': 436,\n",
       " 'minutes': 437,\n",
       " 'cut': 438,\n",
       " 'department': 439,\n",
       " 'even': 440,\n",
       " 'several': 441,\n",
       " 'th': 442,\n",
       " 'gives': 443,\n",
       " 'garlic': 444,\n",
       " 'circulating': 445,\n",
       " 'families': 446,\n",
       " 'system': 447,\n",
       " 'german': 448,\n",
       " 'including': 449,\n",
       " 'orders': 450,\n",
       " 'diyas': 451,\n",
       " 'images': 452,\n",
       " 'must': 453,\n",
       " 'affected': 454,\n",
       " 'updates': 455,\n",
       " 'equipment': 456,\n",
       " 'old': 457,\n",
       " 'leave': 458,\n",
       " 'across': 459,\n",
       " 'c': 460,\n",
       " 'full': 461,\n",
       " 'premier': 462,\n",
       " 'leaders': 463,\n",
       " 'car': 464,\n",
       " 'false': 465,\n",
       " 'stranded': 466,\n",
       " 'helps': 467,\n",
       " 'fire': 468,\n",
       " 'private': 469,\n",
       " 'airport': 470,\n",
       " 'stimulus': 471,\n",
       " 'companies': 472,\n",
       " 'treated': 473,\n",
       " 'captain': 474,\n",
       " 'school': 475,\n",
       " 'schools': 476,\n",
       " 'asked': 477,\n",
       " 'russian': 478,\n",
       " 'colombia': 479,\n",
       " 'fear': 480,\n",
       " 'tom': 481,\n",
       " 'asks': 482,\n",
       " 'ship': 483,\n",
       " 'meeting': 484,\n",
       " 'punjab': 485,\n",
       " 'donate': 486,\n",
       " 'business': 487,\n",
       " 'big': 488,\n",
       " 'navy': 489,\n",
       " 'given': 490,\n",
       " 'related': 491,\n",
       " 'bronx': 492,\n",
       " 'hand': 493,\n",
       " 'know': 494,\n",
       " 'come': 495,\n",
       " 'left': 496,\n",
       " 'blood': 497,\n",
       " 'center': 498,\n",
       " 'making': 499,\n",
       " 'sees': 500,\n",
       " 'good': 501,\n",
       " 'save': 502,\n",
       " 'lanka': 503,\n",
       " 'young': 504,\n",
       " 'women': 505,\n",
       " 'suicide': 506,\n",
       " 'supermarket': 507,\n",
       " 'another': 508,\n",
       " 'takes': 509,\n",
       " 'mother': 510,\n",
       " 'indias': 511,\n",
       " 'sent': 512,\n",
       " 'mayor': 513,\n",
       " 'billion': 514,\n",
       " 'international': 515,\n",
       " 'research': 516,\n",
       " 'nobel': 517,\n",
       " 'germany': 518,\n",
       " 'wife': 519,\n",
       " 'essential': 520,\n",
       " 'season': 521,\n",
       " 'st': 522,\n",
       " 'chain': 523,\n",
       " 'couple': 524,\n",
       " 'canada': 525,\n",
       " 'australian': 526,\n",
       " 'want': 527,\n",
       " 'son': 528,\n",
       " 'offers': 529,\n",
       " 'end': 530,\n",
       " 'experts': 531,\n",
       " 'vitamin': 532,\n",
       " 'release': 533,\n",
       " 'caption': 534,\n",
       " 'outside': 535,\n",
       " 'getting': 536,\n",
       " 'lack': 537,\n",
       " 'stating': 538,\n",
       " 'local': 539,\n",
       " 'dioxide': 540,\n",
       " 'cruise': 541,\n",
       " 'banned': 542,\n",
       " 'cdc': 543,\n",
       " 'early': 544,\n",
       " 'ahead': 545,\n",
       " 'better': 546,\n",
       " 'way': 547,\n",
       " 'lights': 548,\n",
       " 'coming': 549,\n",
       " 'offer': 550,\n",
       " 'hope': 551,\n",
       " 'check': 552,\n",
       " 'price': 553,\n",
       " 'months': 554,\n",
       " 'anthony': 555,\n",
       " 'argentina': 556,\n",
       " 'institute': 557,\n",
       " 'gargling': 558,\n",
       " 'confirms': 559,\n",
       " 'poor': 560,\n",
       " 'migrants': 561,\n",
       " 'drink': 562,\n",
       " 'organization': 563,\n",
       " 'kerala': 564,\n",
       " 'treating': 565,\n",
       " 'financial': 566,\n",
       " 'hands': 567,\n",
       " 'likely': 568,\n",
       " 'israel': 569,\n",
       " 'increase': 570,\n",
       " 'donates': 571,\n",
       " 'road': 572,\n",
       " 'foreign': 573,\n",
       " 'information': 574,\n",
       " 'tells': 575,\n",
       " 'warning': 576,\n",
       " 'got': 577,\n",
       " 'african': 578,\n",
       " 'court': 579,\n",
       " 'right': 580,\n",
       " 'named': 581,\n",
       " 'launches': 582,\n",
       " 'continue': 583,\n",
       " 'production': 584,\n",
       " 'part': 585,\n",
       " 'wrestlemania': 586,\n",
       " 'bolsonaro': 587,\n",
       " 'fears': 588,\n",
       " 'fighting': 589,\n",
       " 'turn': 590,\n",
       " 'sports': 591,\n",
       " 'protection': 592,\n",
       " 'makes': 593,\n",
       " 'pune': 594,\n",
       " 'negative': 595,\n",
       " 'near': 596,\n",
       " 'supplies': 597,\n",
       " 'suspended': 598,\n",
       " 'sick': 599,\n",
       " 'bags': 600,\n",
       " 'following': 601,\n",
       " 'kenya': 602,\n",
       " 'taiwan': 603,\n",
       " 'speech': 604,\n",
       " 'soon': 605,\n",
       " 'warm': 606,\n",
       " 'pakistan': 607,\n",
       " 'ireland': 608,\n",
       " 'month': 609,\n",
       " 'look': 610,\n",
       " 'period': 611,\n",
       " 'saudi': 612,\n",
       " 'interview': 613,\n",
       " 'security': 614,\n",
       " 'law': 615,\n",
       " 'europe': 616,\n",
       " 'tally': 617,\n",
       " 'never': 618,\n",
       " 'everyone': 619,\n",
       " 'supply': 620,\n",
       " 'dying': 621,\n",
       " 'jail': 622,\n",
       " 'walker': 623,\n",
       " 'six': 624,\n",
       " 'forward': 625,\n",
       " 'contact': 626,\n",
       " 'ronaldo': 627,\n",
       " 'goalcom': 628,\n",
       " 'fall': 629,\n",
       " 'behind': 630,\n",
       " 'different': 631,\n",
       " 'meet': 632,\n",
       " 'coffins': 633,\n",
       " 'kids': 634,\n",
       " 'mark': 635,\n",
       " 'letter': 636,\n",
       " 'passengers': 637,\n",
       " 'america': 638,\n",
       " 'child': 639,\n",
       " 'owner': 640,\n",
       " 'videos': 641,\n",
       " 'duterte': 642,\n",
       " 'forced': 643,\n",
       " 'ginger': 644,\n",
       " 'selling': 645,\n",
       " 'appeal': 646,\n",
       " 'well': 647,\n",
       " 'internet': 648,\n",
       " 'guidelines': 649,\n",
       " 'carrying': 650,\n",
       " 'millions': 651,\n",
       " 'charles': 652,\n",
       " 'congress': 653,\n",
       " 'elderly': 654,\n",
       " 'professor': 655,\n",
       " 'gov': 656,\n",
       " 'eu': 657,\n",
       " 'ban': 658,\n",
       " 'map': 659,\n",
       " 'football': 660,\n",
       " 'joe': 661,\n",
       " 'advice': 662,\n",
       " 'shot': 663,\n",
       " 'nation': 664,\n",
       " 'gave': 665,\n",
       " 'contracting': 666,\n",
       " 'cash': 667,\n",
       " 'francis': 668,\n",
       " 'special': 669,\n",
       " 'provide': 670,\n",
       " 'june': 671,\n",
       " 'war': 672,\n",
       " 'ready': 673,\n",
       " 'far': 674,\n",
       " 'start': 675,\n",
       " 'scientist': 676,\n",
       " 'moment': 677,\n",
       " 'low': 678,\n",
       " 'london': 679,\n",
       " 'demand': 680,\n",
       " 'combat': 681,\n",
       " 'announces': 682,\n",
       " 'healthcare': 683,\n",
       " 'criminal': 684,\n",
       " 'mosque': 685,\n",
       " 'la': 686,\n",
       " 'allowed': 687,\n",
       " 'iran': 688,\n",
       " 'immune': 689,\n",
       " 'west': 690,\n",
       " 'italians': 691,\n",
       " 'reaches': 692,\n",
       " 'small': 693,\n",
       " 'program': 694,\n",
       " 'went': 695,\n",
       " 'county': 696,\n",
       " 'foundation': 697,\n",
       " 'place': 698,\n",
       " 'possible': 699,\n",
       " 'cuts': 700,\n",
       " 'book': 701,\n",
       " 'visit': 702,\n",
       " 'hotels': 703,\n",
       " 'honjo': 704,\n",
       " 'flight': 705,\n",
       " 'pneumonia': 706,\n",
       " 'usa': 707,\n",
       " 'train': 708,\n",
       " 'district': 709,\n",
       " 'future': 710,\n",
       " 'approved': 711,\n",
       " 'held': 712,\n",
       " 'seconds': 713,\n",
       " 'contain': 714,\n",
       " 'black': 715,\n",
       " 'rodrigo': 716,\n",
       " 'tamil': 717,\n",
       " 'seen': 718,\n",
       " 'reduce': 719,\n",
       " 'central': 720,\n",
       " 'monday': 721,\n",
       " 'men': 722,\n",
       " 'took': 723,\n",
       " 'act': 724,\n",
       " 'flights': 725,\n",
       " 'club': 726,\n",
       " 'officers': 727,\n",
       " 'channel': 728,\n",
       " 'access': 729,\n",
       " 'launch': 730,\n",
       " 'indians': 731,\n",
       " 'tens': 732,\n",
       " 'proves': 733,\n",
       " 'source': 734,\n",
       " 'statement': 735,\n",
       " 'users': 736,\n",
       " 'turkey': 737,\n",
       " 'cuomo': 738,\n",
       " 'european': 739,\n",
       " 'vaccination': 740,\n",
       " 'stocks': 741,\n",
       " 'warned': 742,\n",
       " 'attributed': 743,\n",
       " 'highest': 744,\n",
       " 'action': 745,\n",
       " 'flouting': 746,\n",
       " 'region': 747,\n",
       " 'animals': 748,\n",
       " 'long': 749,\n",
       " 'worker': 750,\n",
       " 'tokyo': 751,\n",
       " 'key': 752,\n",
       " 'sign': 753,\n",
       " 'thanks': 754,\n",
       " 'seeks': 755,\n",
       " 'diagnosed': 756,\n",
       " 'candles': 757,\n",
       " 'birthday': 758,\n",
       " 'follow': 759,\n",
       " 'lamps': 760,\n",
       " 'ruby': 761,\n",
       " 'tasuku': 762,\n",
       " 'survive': 763,\n",
       " 'border': 764,\n",
       " 'obama': 765,\n",
       " 'responsible': 766,\n",
       " 'deal': 767,\n",
       " 'told': 768,\n",
       " 'others': 769,\n",
       " 'hits': 770,\n",
       " 'living': 771,\n",
       " 'disinfectant': 772,\n",
       " 'member': 773,\n",
       " 'ward': 774,\n",
       " 'shut': 775,\n",
       " 'corpses': 776,\n",
       " 'drop': 777,\n",
       " 'crowd': 778,\n",
       " 'ph': 779,\n",
       " 'extended': 780,\n",
       " 'press': 781,\n",
       " 'nizamuddin': 782,\n",
       " 'cold': 783,\n",
       " 'surgeon': 784,\n",
       " 'caught': 785,\n",
       " 'needed': 786,\n",
       " 'investigation': 787,\n",
       " 'daughter': 788,\n",
       " 'vinegar': 789,\n",
       " 'director': 790,\n",
       " 'dempsey': 791,\n",
       " 'korea': 792,\n",
       " 'education': 793,\n",
       " 'steam': 794,\n",
       " 'beach': 795,\n",
       " 'groups': 796,\n",
       " 'efforts': 797,\n",
       " 'crore': 798,\n",
       " 'yet': 799,\n",
       " 'ordered': 800,\n",
       " 'putin': 801,\n",
       " 'talks': 802,\n",
       " 'power': 803,\n",
       " 'england': 804,\n",
       " 'mp': 805,\n",
       " 'impact': 806,\n",
       " 'election': 807,\n",
       " 'stated': 808,\n",
       " 'area': 809,\n",
       " 'mobile': 810,\n",
       " 'scotland': 811,\n",
       " 'plans': 812,\n",
       " 'phone': 813,\n",
       " 'registered': 814,\n",
       " 'bats': 815,\n",
       " 'singh': 816,\n",
       " 'started': 817,\n",
       " 'safety': 818,\n",
       " 'night': 819,\n",
       " 'biological': 820,\n",
       " 'telangana': 821,\n",
       " 'classes': 822,\n",
       " 'john': 823,\n",
       " 'clip': 824,\n",
       " 'buying': 825,\n",
       " 'warn': 826,\n",
       " 'markets': 827,\n",
       " 'salary': 828,\n",
       " 'might': 829,\n",
       " 'singapore': 830,\n",
       " 'park': 831,\n",
       " 'governments': 832,\n",
       " 'huge': 833,\n",
       " 'contracted': 834,\n",
       " 'cristiano': 835,\n",
       " 'hancock': 836,\n",
       " 'exercise': 837,\n",
       " 'messages': 838,\n",
       " 'find': 839,\n",
       " 'visited': 840,\n",
       " 'areas': 841,\n",
       " 'mandatory': 842,\n",
       " 'cities': 843,\n",
       " 'manchester': 844,\n",
       " 'receive': 845,\n",
       " 'repeatedly': 846,\n",
       " 'korean': 847,\n",
       " 'noida': 848,\n",
       " 'stayathome': 849,\n",
       " 'result': 850,\n",
       " 'kits': 851,\n",
       " 'consuming': 852,\n",
       " 'nadu': 853,\n",
       " 'beds': 854,\n",
       " 'extends': 855,\n",
       " 'protest': 856,\n",
       " 'summer': 857,\n",
       " 'actor': 858,\n",
       " 'religious': 859,\n",
       " 'percent': 860,\n",
       " 'rare': 861,\n",
       " 'administration': 862,\n",
       " 'holy': 863,\n",
       " 'run': 864,\n",
       " 'tips': 865,\n",
       " 'conspiracy': 866,\n",
       " 'boy': 867,\n",
       " 'viruses': 868,\n",
       " 'recorded': 869,\n",
       " 'record': 870,\n",
       " 'planned': 871,\n",
       " 'role': 872,\n",
       " 'lockdowns': 873,\n",
       " 'much': 874,\n",
       " 'jump': 875,\n",
       " 'half': 876,\n",
       " 'modis': 877,\n",
       " 'lankan': 878,\n",
       " 'kicker': 879,\n",
       " 'track': 880,\n",
       " 'stopped': 881,\n",
       " 'shutdown': 882,\n",
       " 'suggests': 883,\n",
       " 'asking': 884,\n",
       " 'singer': 885,\n",
       " 'records': 886,\n",
       " 'ensure': 887,\n",
       " 'technology': 888,\n",
       " 'deadly': 889,\n",
       " 'available': 890,\n",
       " 'seven': 891,\n",
       " 'tweet': 892,\n",
       " 'details': 893,\n",
       " 'networks': 894,\n",
       " 'prayers': 895,\n",
       " 'capital': 896,\n",
       " 'history': 897,\n",
       " 'ways': 898,\n",
       " 'game': 899,\n",
       " 'immunity': 900,\n",
       " 'opinion': 901,\n",
       " 'ghana': 902,\n",
       " 'red': 903,\n",
       " 'evidence': 904,\n",
       " 'form': 905,\n",
       " 'throat': 906,\n",
       " 'girl': 907,\n",
       " 'numbers': 908,\n",
       " 'easter': 909,\n",
       " 'wwe': 910,\n",
       " 'solidarity': 911,\n",
       " 'transmission': 912,\n",
       " 'beaten': 913,\n",
       " 'forces': 914,\n",
       " 'goes': 915,\n",
       " 'shopping': 916,\n",
       " 'panic': 917,\n",
       " 'room': 918,\n",
       " 'transmitted': 919,\n",
       " 'matt': 920,\n",
       " 'decision': 921,\n",
       " 'insurance': 922,\n",
       " 'pastor': 923,\n",
       " 'cops': 924,\n",
       " 'coach': 925,\n",
       " 'gas': 926,\n",
       " 'husband': 927,\n",
       " 'common': 928,\n",
       " 'prevention': 929,\n",
       " 'holds': 930,\n",
       " 'lakh': 931,\n",
       " 'king': 932,\n",
       " 'furlough': 933,\n",
       " 'personal': 934,\n",
       " 'worst': 935,\n",
       " 'prince': 936,\n",
       " 'someone': 937,\n",
       " 'reach': 938,\n",
       " 'bus': 939,\n",
       " 'needs': 940,\n",
       " 'products': 941,\n",
       " 'political': 942,\n",
       " 'admits': 943,\n",
       " 'ventilator': 944,\n",
       " 'chlorine': 945,\n",
       " 'nationwide': 946,\n",
       " 'florida': 947,\n",
       " 'liverpool': 948,\n",
       " 'contains': 949,\n",
       " 'walking': 950,\n",
       " 'recovered': 951,\n",
       " 'count': 952,\n",
       " 'prison': 953,\n",
       " 'known': 954,\n",
       " 'industry': 955,\n",
       " 'store': 956,\n",
       " 'various': 957,\n",
       " 'lions': 958,\n",
       " 'hiv': 959,\n",
       " 'lot': 960,\n",
       " 'union': 961,\n",
       " 'uttar': 962,\n",
       " 'package': 963,\n",
       " 'nyc': 964,\n",
       " 'suspected': 965,\n",
       " 'instagram': 966,\n",
       " 'hotel': 967,\n",
       " 'side': 968,\n",
       " 'nearly': 969,\n",
       " 'facing': 970,\n",
       " 'narendra': 971,\n",
       " 'alarm': 972,\n",
       " 'pictures': 973,\n",
       " 'suffering': 974,\n",
       " 'conference': 975,\n",
       " 'breaks': 976,\n",
       " 'spitting': 977,\n",
       " 'purported': 978,\n",
       " 'steps': 979,\n",
       " 'ago': 980,\n",
       " 'prices': 981,\n",
       " 'ceo': 982,\n",
       " 'head': 983,\n",
       " 'within': 984,\n",
       " 'job': 985,\n",
       " 'great': 986,\n",
       " 'nigerian': 987,\n",
       " 'egypt': 988,\n",
       " 'love': 989,\n",
       " 'lying': 990,\n",
       " 'ask': 991,\n",
       " 'hair': 992,\n",
       " 'manufactured': 993,\n",
       " 'results': 994,\n",
       " 'starmer': 995,\n",
       " 'governors': 996,\n",
       " 'pcr': 997,\n",
       " 'station': 998,\n",
       " 'lord': 999,\n",
       " 'move': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "hSSC_p3S_G52"
   },
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "X_test = pad_sequences(tokenized_test, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VShdUe1m_G56"
   },
   "source": [
    "# Preparing embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7bcmA6q_G56"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CheemUFh_G5-"
   },
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Kx7sSQe_G5_"
   },
   "outputs": [],
   "source": [
    "def lstm_net1():\n",
    "    model = Sequential()\n",
    "\n",
    "    #Non-trainable embeddidng layer\n",
    "    model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    \n",
    "    model.add(LSTM(units=128 , return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=64))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units = 32 , activation = 'relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zj6NdGzk_G6C",
    "outputId": "21dc134a-bf91-447b-afd9-ae7c9986b4b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 300)          5085600   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 500, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,356,769\n",
      "Trainable params: 271,169\n",
      "Non-trainable params: 5,085,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#training an LSTM network\n",
    "model2 = lstm_net1()\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 8\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKn9a5Sl_G6F",
    "outputId": "b01e139d-8f5b-49cd-d1ec-32e66fa10bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "56/56 [==============================] - 35s 217ms/step - loss: 0.6778 - accuracy: 0.5744 - val_loss: 0.6098 - val_accuracy: 0.6465\n",
      "Epoch 2/8\n",
      "56/56 [==============================] - 11s 198ms/step - loss: 0.6022 - accuracy: 0.6521 - val_loss: 0.5782 - val_accuracy: 0.6985\n",
      "Epoch 3/8\n",
      "56/56 [==============================] - 11s 197ms/step - loss: 0.5492 - accuracy: 0.7044 - val_loss: 0.5160 - val_accuracy: 0.7271\n",
      "Epoch 4/8\n",
      "56/56 [==============================] - 11s 198ms/step - loss: 0.4948 - accuracy: 0.7528 - val_loss: 0.5057 - val_accuracy: 0.7411\n",
      "Epoch 5/8\n",
      "56/56 [==============================] - 11s 199ms/step - loss: 0.4919 - accuracy: 0.7555 - val_loss: 0.4756 - val_accuracy: 0.7646\n",
      "Epoch 6/8\n",
      "56/56 [==============================] - 11s 199ms/step - loss: 0.4619 - accuracy: 0.7712 - val_loss: 0.5562 - val_accuracy: 0.7132\n",
      "Epoch 7/8\n",
      "56/56 [==============================] - 11s 196ms/step - loss: 0.5059 - accuracy: 0.7487 - val_loss: 0.4562 - val_accuracy: 0.7842\n",
      "Epoch 8/8\n",
      "56/56 [==============================] - 11s 196ms/step - loss: 0.4501 - accuracy: 0.7857 - val_loss: 0.4505 - val_accuracy: 0.7916\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07_mwkKb_G6I"
   },
   "source": [
    "# LSTM Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "I023VeD7_G6I",
    "outputId": "1448d016-cedc-43cd-c18d-1db92e811fdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f83ae4d1ad0>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model2.predict_classes(X_test)\n",
    "cf_matrix = confusion_matrix(y_test,pred)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g', xticklabels = ['Fake','Real'] , yticklabels = ['Fake','Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EvsGeQs_G6M",
    "outputId": "c1d05cda-c92a-455e-e244-d01402397634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.7914959212993794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred)\n",
    "print(\"AUC score is \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfh8ImM8_G6P",
    "outputId": "b211790e-d0da-467f-a010-b22e04518170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 0.7915268457728903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "F1_score = f1_score(y_test, pred, average='macro')\n",
    "print(\"F1 score is\", F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vaWQBKZz_G6S",
    "outputId": "c84b7a00-efeb-4e08-eeb7-f30d90b775d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy is  0.7915956842703009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, pred)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qThWT9NBaeP"
   },
   "source": [
    "# **CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "domvzc8RBxqK"
   },
   "outputs": [],
   "source": [
    "def cnn_net1():\n",
    "  model = Sequential()\n",
    "\n",
    "  #Non-trainable embeddidng layer\n",
    "  model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "  \n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Conv1D(filters=128, kernel_size=4, activation='relu'))\n",
    "  model.add(GlobalMaxPooling1D())\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(units = 250 , activation = 'relu'))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "def get_pred_output(text_to_check):\n",
    "  sequences = tokenizer.texts_to_sequences([text_to_check])\n",
    "  data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "  predicted_val = model.predict_classes(data)\n",
    "#     predicted_val = model.predict(data)    \n",
    "#     if predicted_val.max() > 0.7:\n",
    "#         output = 1\n",
    "#     else:\n",
    "#         output = 0\n",
    "  return predicted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkZC1MHJB_sH",
    "outputId": "44930c92-b4fe-430d-e78a-1688b65e8e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 300)          5085600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 497, 128)          153728    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               32250     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 5,271,829\n",
      "Trainable params: 186,229\n",
      "Non-trainable params: 5,085,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train a 1D convnet with global maxpooling\n",
    "model_1 = cnn_net1()\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 8\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bq5-oS5f_G6y",
    "outputId": "cee690f0-ade6-4248-f191-f3aad70ab4ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "56/56 [==============================] - 32s 107ms/step - loss: 0.6760 - accuracy: 0.5721 - val_loss: 0.5470 - val_accuracy: 0.7266\n",
      "Epoch 2/8\n",
      "56/56 [==============================] - 6s 101ms/step - loss: 0.5203 - accuracy: 0.7512 - val_loss: 0.4187 - val_accuracy: 0.8095\n",
      "Epoch 3/8\n",
      "56/56 [==============================] - 6s 100ms/step - loss: 0.3976 - accuracy: 0.8265 - val_loss: 0.3988 - val_accuracy: 0.8197\n",
      "Epoch 4/8\n",
      "56/56 [==============================] - 6s 100ms/step - loss: 0.3241 - accuracy: 0.8646 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
      "Epoch 5/8\n",
      "56/56 [==============================] - 6s 100ms/step - loss: 0.2533 - accuracy: 0.8995 - val_loss: 0.3139 - val_accuracy: 0.8651\n",
      "Epoch 6/8\n",
      "56/56 [==============================] - 6s 100ms/step - loss: 0.2124 - accuracy: 0.9181 - val_loss: 0.3000 - val_accuracy: 0.8734\n",
      "Epoch 7/8\n",
      "56/56 [==============================] - 6s 100ms/step - loss: 0.1922 - accuracy: 0.9243 - val_loss: 0.3259 - val_accuracy: 0.8648\n",
      "Epoch 8/8\n",
      "56/56 [==============================] - 6s 99ms/step - loss: 0.1463 - accuracy: 0.9452 - val_loss: 0.3303 - val_accuracy: 0.8671\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(X_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "LpBtr8mDHSyc",
    "outputId": "7c839e93-6954-4e20-910f-82445f5bf122"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f83af710d50>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAc90lEQVR4nO3de5xVdb3/8debGa4SNxFUMAFFPd5IJcTMK+VdQC3DTFHJycLsmHlLO5Rdj7+OpmUXVFL7qXhJk5STB0kzOyFCAop4mURhRpQUARVQZuZz/tgL3HKZ2TPsPXvN4v30sR6s/V3ftb/f5czjw5fP+q7vUkRgZmbp0q7cHTAzs405OJuZpZCDs5lZCjk4m5mlkIOzmVkKVZa6gdV3fc/TQWwjp1z8ZLm7YCk0ddFUbel3rH3z5YJjTvveg7a4vVLxyNnMLIVKPnI2M2tVDfXl7kFRODibWbbU15W7B0Xh4GxmmRLRUO4uFIWDs5llS0M2grNvCJpZtkRD4VsTJE2StFTSsxuUf13S85LmS7o6r/xySdWSXpB0dF75MUlZtaTLCrkMj5zNLFuKe0PwFuAXwG3rCiQdAYwChkTE+5L6JOV7AmOAvYAdgUck7ZacdgPwWaAGeErSlIh4rrGGHZzNLFuKmHOOiMclDdig+KvATyLi/aTO0qR8FDA5KV8oqRoYlhyrjoiXASRNTuo2Gpyd1jCzTIn6uoI3SVWSZuVtVQU0sRtwiKQnJf1F0ieT8n7A4rx6NUnZ5sob5ZGzmWVLM24IRsREYGIzW6gEegHDgU8Cd0sa1MzvKKgRM7PsKP1Uuhrgvsi9qWSmpAagN1AL7JRXr39SRiPlm+W0hpllS0N94VvL/AE4AiC54dcBeBOYAoyR1FHSQGAwMBN4ChgsaaCkDuRuGk5pqhGPnM0sW4o4cpZ0J3A40FtSDTABmARMSqbXfQCMTUbR8yXdTe5GXx0wPiLqk+85H3gYqAAmRcT8ptp2cDazbCni49sRcdpmDn1pM/V/CPxwE+VTganNadvB2cyyJSNPCDo4m1mmJJmENs/B2cyyxQsfmZmlkNMaZmYp5JGzmVkK1a8tdw+KwsHZzLLFaQ0zsxRyWsPMLIU8cjYzSyEHZzOz9AnfEDQzSyHnnM3MUshpDTOzFPLI2cwshTxyNjNLIY+czcxSqK54i+2Xk4OzmWVLRkbOfsGrmWVLQ0PhWxMkTZK0NHlf4IbHLpIUknonnyXpeknVkuZJ2j+v7lhJLyXb2EIuw8HZzLIlGgrfmnYLcMyGhZJ2Ao4CFuUVH0vujduDgSrgV0ndXuReDHsgMAyYIKlnUw07OJtZthRx5BwRjwPLNnHoWuASIPLKRgG3Rc4MoIekHYCjgWkRsSwi3gamsYmAvyHnnM0sW0qcc5Y0CqiNiLmS8g/1Axbnfa5JyjZX3igHZzPLlmbM1pBURS4Fsc7EiJjYSP0uwLfJpTRKysHZzLIlouk666vGRGCzwXgTdgEGAutGzf2Bf0gaBtQCO+XV7Z+U1QKHb1D+WFMNOedsZtlSxJzzhiLimYjoExEDImIAuRTF/hHxOjAFODOZtTEcWBERS4CHgaMk9UxuBB6VlDXKI2czy5YiPr4t6U5yo97ekmqACRFx82aqTwWOA6qBVcDZABGxTNL3gaeSeldFxKZuMn6Eg7OZZUsRbwhGxGlNHB+Qtx/A+M3UmwRMak7bDs5mli319eXuQVE4OJtZtnhVOjOzFHJwNjNLoYwsfOTgbGaZEg2Fz3NOMwdnM8sWpzXMzFLIszXMzFLII2czsxRycDaACffP4PEXa+m1TSd+f/7xANwwfS6PPV+LBL226cRVJw2nT7curFz9ARP+MIOaZe/SobId3xs9nF379gDgby+9xtVTZ9MQwUn778I5h+5VzsuyImnfsT1X33M17Tu0p6KygiemPsHt19zOkIOHMO7b41A7sWbVGq755jUseXUJ5/7Huex70L4AdOrcie7bdufUfU4t81W0Mc1Y+CjNHJy30Mj9BjHmwN248r6/ry8be/CejB8xBIA7ZrzAxMee5cqRw7jp8fnsvn1Prj3tUBb+awU/fnAWE88eQX1DAz9+cBa/Hnskfbt15vTfPMxhe/Rnlz7dy3VZViRr31/L5WMuZ82qNVRUVvDT3/+UWY/O4vwfns9VX76KxdWLOf6M4xlzwRiuvehabrzqxvXnnnjWieyy1y5l7H0blZGRs1el20IHDOhDt84dPlLWtVP79furP6hj3XrcLy9dwbCBfQEYuF13Xlv+Hm+9u5pna95ip15d6d+rK+0rKzh6n5157PmaVrsGK601q9YAUFlZSUVlBQREBF26dgFgm27bsOyNjdfBOWzkYfxlyl9ata+Z0BCFbylW0MhZ0m7k3ofVNyL2lrQvMDIiflDS3rVhP39kLg/OWUjXTu258ewRAOy2fQ+mL1jM/gP68EzNmyxZ8R5vrFzN0ndWs333bdaf27dbF56pebNcXbcia9euHdc9dB07DtiRB297kBfmvMB1l17H9279Hh+s+YBV767iwlEXfuScPv36sP3Ht2fu3+aWqddtWEZmaxQ6cr4RuBxYCxAR84Axm6ssqUrSLEmzbn5k1pb3sg36+meG8PC3RnPcvgOY/OSLAJxzyF68s2Ytp/5yKpOffJHdt+9Ju4++5sYyqKGhga8f+3XOPPBMdhuyGzvvtjOjx41mwtgJnHngmUy7expV36n6yDmHjjyUJx56goaM/BO9NUVDQ8FbmhUanLtExMwNyjb7LpiImBgRQyNi6LjPDG157zLguH0HMP253OvDunZqz1UnDefurx3HD04+iLdXvU//nl3p87HOvL7ivfXnvLFyFX26dSlXl61E3lv5HvP+Po+hRwxl0J6DeGHOCwA8/sfH+beh//aRuoed6JRGi2UkrVFocH5T0i4kb5qV9DlgScl61ca9+tbK9fuPPV/DwN7dAFi5+gPW1uX+yXXf7H9ywM7b0bVTe/bqty2Llr1D7dvvsraunoefeZXD9mjy/Y/WBnTr1Y1tuuVSVh06dmC/Q/ZjcfViunysC/0G5n7G+x2yH4tf+vD9n/136U/X7l1ZMHtBWfrc5kVD4VuKFTpbYzy592ztIakWWAicXrJetSGX3fM3Zi18g+Wr3ueon97PV4/Ylydeeo1X3lxJO4kdunfhipHDAFj4rxV85/4ZCNilT3e+O3o4AJUV7bjs+KF89bZHaWgIRu0/iF379CjjVVmx9OrTi4uuuYh2Fe1QO/HXB//KzOkzuf7S67niN1fQ0NDAuyve5WcX/2z9OYeNPIy//NGj5hZL+Yi4UIoC5gRKOiAiZkvaBmgXEe9IOiEiHmzq3NV3fS8b/6esqE65+Mlyd8FSaOqiqVt8E+a9/xhTcMzZ5qrJqb3pU/ANQUl7R8R7SWAeA3ynlB0zM2uRjKQ1Cg3OnwNuk7SHpHPJpTmOKl23zMxaqIg3BCVNkrRU0rN5Zf9P0vOS5km6X1KPvGOXS6qW9IKko/PKj0nKqiVdVshlFBScI+JlclPn7gNOAY6KiBWFnGtm1pqKPJXuFuCYDcqmAXtHxL7Ai+SmGSNpT3Jxcq/knF9KqpBUAdwAHAvsCZyW1G1UozcEJT1DMkMj0QuoAJ6URNI5M7P0KOINwYh4XNKADcr+J+/jDHKZBYBRwOSIeB9YKKkaGJYcq04GuUianNR9rrG2m5qtcUIhF2BmlhrNCM6SqoD8J4AmRsTEZrR2DnBXst+PXLBepyYpA1i8QfmBTX1xo8E5Il7N/yypD9CpqS81MyubZjy+nQTi5gTj9SRdQe5hvNtbcn5TCl1bYyTwX8COwFJgZ2ABudyKmVlqtMY7BCWdRS6zMCI+nI9cC+yUV61/UkYj5ZtV6GyN7wPDgRcjYiAwgo8O383M0qHEj29LOga4hNzib6vyDk0BxkjqKGkgMBiYCTwFDJY0UFIHcjcNpzTVTqFPCK6NiLcktZPULiIelfSzpk8zM2tlRVzQSNKdwOFAb0k1wARyszM6AtOUW7hsRkScFxHzJd1N7kZfHTA+IuqT7zkfeJjchIpJETG/qbYLDc7LJXUFHgdul7QUeK+Jc8zMWl9xZ2uctonimxup/0Pgh5sonwpMbU7bjaY1JH082R0FrAIuBP4E/BM4sTkNmZm1ioysStfUyPkPwP4R8Z6k30fEKcCtrdAvM7MWifp0P5ZdqKaCc/6iIINK2REzs6JI+Yi4UE0F59jMvplZKrXGVLrW0FRwHiJpJbkRdOdkn+RzRES3kvbOzKy5tobgHBEVrdURM7OiyEbKueCpdGZmbULUZSM6OzibWbZkIzY7OJtZtmwtNwTNzNoWj5zNzNLHI2czszTyyNnMLH2irtw9KA4HZzPLlPDI2cwshRyczczSxyNnM7MUcnA2M0uhqFfTldqAQl/wambWJkRD4VtTJE2StFTSs3llvSRNk/RS8mfPpFySrpdULWmepP3zzhmb1H9J0thCrsPB2cwyJRpU8FaAW4BjNii7DJgeEYOB6clngGPJvXF7MFAF/ApywZzci2EPBIYBE9YF9MY4OJtZphRz5BwRjwPLNigexYev67sVGJ1XflvkzAB6SNoBOBqYFhHLIuJtYBobB/yNOOdsZpkSUfKcc9+IWJLsvw70Tfb7AYvz6tUkZZsrb5RHzmaWKc0ZOUuqkjQrb6tqVlsRQYle4eeRs5llSkMzZmtExERgYjObeEPSDhGxJElbLE3Ka4Gd8ur1T8pqgcM3KH+sqUY8cjazTCnyDcFNmQKsm3ExFnggr/zMZNbGcGBFkv54GDhKUs/kRuBRSVmjPHI2s0zZgqC7EUl3khv19pZUQ27WxU+AuyWNA14FTk2qTwWOA6qBVcDZABGxTNL3gaeSeldFxIY3GTfi4GxmmRJFzABHxGmbOTRiE3UDGL+Z75kETGpO2w7OZpYpxRw5l5ODs5llSitMpWsVDs5mlin1GVlbw8HZzDLFI2czsxRyztnMLIWKOVujnByczSxTPHI2M0uh+oZsPPjs4GxmmeK0hplZCjV4toaZWfp4Kp2ZWQo5rVGgj53R3KVSbWuw+rW/lrsLllFOa5iZpZBna5iZpVBGshoOzmaWLU5rmJmlkGdrmJmlUEO5O1AkDs5mlilBNkbO2bitaWaWqAsVvDVF0oWS5kt6VtKdkjpJGijpSUnVku6S1CGp2zH5XJ0cH7Al1+HgbGaZEqjgrTGS+gEXAEMjYm+gAhgD/CdwbUTsCrwNjEtOGQe8nZRfm9RrMQdnM8uUhmZsBagEOkuqBLoAS4AjgXuT47cCo5P9UclnkuMjJLU4x+LgbGaZ0pyRs6QqSbPytqr13xNRC/wUWEQuKK8AZgPLI6IuqVYD9Ev2+wGLk3PrkvrbtvQ6fEPQzDKlObM1ImIisMk1JiT1JDcaHggsB+4BjtniDhbIwdnMMqW+eLM1PgMsjIh/AUi6DzgY6CGpMhkd9wdqk/q1wE5ATZIG6Q681dLGndYws0xpUOFbExYBwyV1SXLHI4DngEeBzyV1xgIPJPtTks8kx/8c0fI18jxyNrNMaSjSyDkinpR0L/APoA54mlwK5CFgsqQfJGU3J6fcDPxOUjWwjNzMjhZzcDazTCnmwkcRMQGYsEHxy8CwTdRdA3y+WG07OJtZpvjxbTOzFGpo+dTiVHFwNrNMqS93B4rEwdnMMqWAWRhtgoOzmWVKsWZrlJuDs5llil9TZWaWQk5rmJmlkKfSmZmlUL1HzmZm6eORs5lZCjk4m5mlUAGvBmwTHJzNLFM8cjYzSyE/vm1mlkKe52xmlkJOa5iZpZCDs5lZCmVlbQ2/4NXMMqWIL3hFUg9J90p6XtICSQdJ6iVpmqSXkj97JnUl6XpJ1ZLmSdp/S67DwdnMMqW+GVsBrgP+FBF7AEOABcBlwPSIGAxMTz4DHAsMTrYq4Fdbch0OzmaWKQ1EwVtjJHUHDiV5u3ZEfBARy4FRwK1JtVuB0cn+KOC2yJkB9JC0Q0uvw8HZzDKloRlbEwYC/wJ+K+lpSTdJ2gboGxFLkjqvA32T/X7A4rzza5KyFnFwNrNMiWZskqokzcrbqvK+qhLYH/hVROwHvMeHKYxcWxHrvqroPFvDzDKlOVPpImIiMHEzh2uAmoh4Mvl8L7ng/IakHSJiSZK2WJocrwV2yju/f1LWIh45m1mm1CkK3hoTEa8DiyXtnhSNAJ4DpgBjk7KxwAPJ/hTgzGTWxnBgRV76o9k8cjazTClyjuHrwO2SOgAvA2eTG9TeLWkc8CpwalJ3KnAcUA2sSuq2mIOzmWVKMZ8QjIg5wNBNHBqxiboBjC9W2w7OZpYpTU2RayscnM0sU7IRmh2czSxjvPCRmVkK1Wdk7OzgbGaZ4pGzmVkKhUfOZmbpk5WRs58QLJFvXHAuc+f8mTlPT+f//+4GOnbsyNe+ehbPP/cEdR/Usu22PcvdRSuhK390DYceP4bRXzrvI+W33/MAJ552LqNO/wr/dcPN68tfqF7I6VUXMur0r3DSGV/l/fc/+Mh551/y3Y2+yzatWKvSlZtHziWw447bc/74c9hnyBGsWbOGO+/4NV84dRT/+/eneGjqI0yfdm+5u2glNvq4z/LFU0by7e//dH3ZzNlzefSJGfz+1hvo0KEDb729HIC6unouu+pqfvydi9lj8CCWr1hJZWXF+vOmPfY3unTp3OrX0FalO+QWziPnEqmsrKRz505UVFTQpXNnlix5nTlz5vPqqzXl7pq1gqGf2Ifu3T72kbK7/vAQ4750Kh06dABg2549APjfmbPZbZeB7DF4EAA9unejoiIXnFetWs1td93HV8aOacXet211RMFbmjk4l8Brr73ONdf+moX/nEnNoqdZsXIl0x55vNzdsjJ7ZVEts+c+y2nn/jtnjb+YZxa8AMCri2uRRNWFV/D5s89n0u33rD/n5zfextgxJ9OpU6dydbvNiWb8l2aNpjUk/ZxG/pUQERds5rwqcq9pQRXdaddumy3pY5vTo0d3Rp54NLvuNpzly1dy1+Tf8MUvnswdd9xX7q5ZGdXX17Ny5TvcMfFanl3wIt/6zo/50z2/pa6+nqfnzWfyTdfRqVNHvnzB5ey5+6706NaNxbVLuPQbX6F2yRvl7n6bkZUbgk3lnGe15Evz10it7NAv3X89lcCIEYew8JVFvPnmMgDu/8N/c9DwoQ7OW7m+fXrzmcMORhL77Lk7knh7+Qr69unNAUP2pmeP7gAcctAnee6Ff9KlSyfmP/8SR50ylvr6et56ewVnnX8Jt/zi6jJfSbqlfURcqEaDc0Tc2thx27TFi2o58MD96dy5E6tXr+HIIz7N7Nlzy90tK7MjDzmImf+Yy7ADhvDKohrW1tXRs0d3Dh52AL+9/V5Wr1lD+8r2zJrzDGd84SQO+9Qwxpx0AgC1S95g/MUTHJgLsLWMnAGQtB1wKbAnsD75FRFHlqhfbdrMp57mvvse4qmZD1NXV8ecOfO58abbOX/8OXzroq+x/fbb8fTsR/jvP/2Zr5x3cbm7ayVw8YSf8NTT81i+fCUjRn+Jr407g5NPOIorf3Qto790Hu3bV/KjKy9CEt27fYwzx5zMmHHfQBKHHPRJDvvUsHJfQptVH9kYOSsKuBBJ/wPcBXwLOI/c6v//iohLmzp3a0xrWNNWv/bXcnfBUqh970Ha0u/44s4nFRxz7nj1/i1ur1QKna2xbUTcDKyNiL9ExDmAR81mljpbxWyNPGuTP5dIOh54DehVmi6ZmbXcVpVzBn4gqTtwEfBzoBtwYcl6ZWbWQml/LLtQBQXniHgw2V0BHFG67piZbZlipyskVZCbVlwbESdIGghMBrYFZgNnRMQHkjoCtwEHAG8BX4iIV1rabkE5Z0m7SZou6dnk876Srmxpo2ZmpVIfUfBWoG8AC/I+/ydwbUTsCrwNjEvKxwFvJ+XXJvVarNAbgjcCl5PkniNiHuCH/c0sdYq5Kp2k/sDxwE3JZ5GbDLFu9bJbgdHJ/qjkM8nxEUn9Fik0OHeJiJkblNW1tFEzs1JpaMYmqUrSrLytaoOv+xlwCR/eZ9wWWB4R6+JfDdAv2e8HLAZIjq9I6rdIoTcE35S0C8k6G5I+ByxpaaNmZqXSnJxz/lITG5J0ArA0ImZLOrw4vStcocF5PLkL2ENSLbAQOL1kvTIza6EiztY4GBgp6ThyT0Z3A64DekiqTEbH/YHapH4tsBNQI6kS6E7uxmCLFJTWiIiXI+IzwHbAHsBhwKdb2qiZWalERMFbE99zeUT0j4gB5O6x/TkiTgceBT6XVBsLPJDsT0k+kxz/cxTyCPZmNBqcJXWTdLmkX0j6LLAqabwaOLWljZqZlUo9UfDWQpcC35RUTS6nvO59YzcD2ybl3wQu25LraCqt8TtyU0X+DpwLXAEIOCki5mxJw2ZmpVCKh1Ai4jHgsWT/ZWCjlakiYg3w+WK12VRwHhQR+wBIuoncTcCPJ50wM0udLcgkpEpTwXndmhpERL2kGgdmM0uzreXx7SGSVib7AjonnwVERHQrae/MzJop7avNFaqpN6FUNHbczCxtsrLYfqHznM3M2oStJa1hZtamODibmaXQ1jJbw8ysTfHI2cwshbaK2RpmZm1NfWTjLYIOzmaWKc45m5mlkHPOZmYp5JyzmVkKNTitYWaWPh45m5mlkGdrmJmlkNMaZmYplJW0RkEveDUzaysaIgreGiNpJ0mPSnpO0nxJ30jKe0maJuml5M+eSbkkXS+pWtI8SftvyXU4OJtZpkQz/mtCHXBRROwJDAfGS9qT3Itbp0fEYGA6H77I9VhgcLJVAb/akutwcDazTKmP+oK3xkTEkoj4R7L/DrAA6AeMAm5Nqt0KjE72RwG3Rc4MoIekHVp6HQ7OZpYpEVHwJqlK0qy8rWpT3ylpALAf8CTQNyKWJIdeB/om+/2AxXmn1SRlLeIbgmaWKc15fDsiJgITG6sjqSvwe+DfI2KlpPzzQ1JJ7kA6OJtZphRz4SNJ7ckF5tsj4r6k+A1JO0TEkiRtsTQprwV2yju9f1LWIk5rmFmmFHG2hoCbgQURcU3eoSnA2GR/LPBAXvmZyayN4cCKvPRHs3nkbGaZUsR5zgcDZwDPSJqTlH0b+Alwt6RxwKvAqcmxqcBxQDWwCjh7Sxp3cDazTCnW49sR8QSgzRwesYn6AYwvSuM4OJtZxnixfTOzFPLaGmZmKeSRs5lZCvk1VWZmKeSRs5lZCnmxfTOzFPINQTOzFHJaw8wshbLyJhQHZzPLFI+czcxSKCs5Z2Xlb5m2QFJVsn6s2Xr+vbBN8ZKhrWuTb1mwrZ5/L2wjDs5mZink4GxmlkIOzq3LeUXbFP9e2EZ8Q9DMLIU8cjYzSyEHZzOzFHJwLgJJ9ZLm5G0DNlNvgKRnW7d3Vi55vxfPSvqjpB4t/J6zJP2i2P2zdHNwLo7VEfGJvO2VcnfIUmHd78XewDKK+PJPyz4H5xKQ1FXSdEn/kPSMpFGbqDNI0tOSPilpF0l/kjRb0l8l7VGOfltJ/R3oB7C5n7ekEyU9mfxePCKpb1l7bGXltTWKo7OkOcn+QuDzwEkRsVJSb2CGpCnrKkvaHZgMnBURcyVNB86LiJckHQj8Ejiyla/BSkRSBTACuDkpmsimf95PAMMjIiR9GbgEuKgcfbbyc3AujtUR8Yl1HyS1B34k6VCggdyIad0oaDvgAeDkiHhOUlfgU8A9ktZ9RcdW67mV0rq/tPsBC4BpTfy8+wN3SdoB6EDuL3rbSjk4l8bp5ILwARGxVtIrQKfk2ApgEfBp4DlyqaXl+cHdMmN1RHxCUhfgYXI551vY/M/758A1ETFF0uHAd1uro5Y+zjmXRndgaRKYjwB2zjv2AXAScKakL0bESmChpM8DKGdI63fZSiUiVgEXkEtRrGLzP+/uQG2yP7bVO2qp4uBcGrcDQyU9A5wJPJ9/MCLeA04ALpQ0ktxIe5ykucB8YKMbiNa2RcTTwDzgNDb/8/4uuXTHbODNcvTT0sOPb5uZpZBHzmZmKeTgbGaWQg7OZmYp5OBsZpZCDs5mZink4GxmlkIOzmZmKfR/L4f4c6YlwcAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model_1.predict_classes(X_test)\n",
    "cf_matrix = confusion_matrix(y_test,pred)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g', xticklabels = ['Fake','Real'] , yticklabels = ['Fake','Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RsLDXcsG6ZR",
    "outputId": "6bfe1700-e5a1-4883-faa8-12d1af841bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.8678994409624411\n",
      "F1 score is 0.8663118294081922\n",
      "Acuracy is  0.8671209540034072\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred)\n",
    "print(\"AUC score is \", auc_score)\n",
    "\n",
    "F1_score = f1_score(y_test, pred, average='macro')\n",
    "print(\"F1 score is\", F1_score)\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, pred)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyxrlVXDfg_c",
    "outputId": "16ea044c-6b9f-49fc-ff32-ab2029c7c5a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe embedding \n",
    "embeddings_index = dict()\n",
    "f = open('/content/gdrive/My Drive/fake-news/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyL2tL2yxaAA"
   },
   "source": [
    "##LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1inCd7Qt6rm"
   },
   "outputs": [],
   "source": [
    "def lstm_net1():\n",
    "    model = Sequential()\n",
    "\n",
    "    #Non-trainable embeddidng layer\n",
    "    model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    \n",
    "    model.add(LSTM(units=128 , return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=64))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units = 32 , activation = 'relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zDig4lRxfxp",
    "outputId": "818fe65f-4f1b-44f7-d245-dcb886bfd279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 300)          5085600   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 500, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,356,769\n",
      "Trainable params: 271,169\n",
      "Non-trainable params: 5,085,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#training an LSTM network\n",
    "model2 = lstm_net1()\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 8\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ttc2vZqjxj60",
    "outputId": "be0a20dc-1919-4e4d-9218-2a00424959db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "56/56 [==============================] - 15s 209ms/step - loss: 0.5258 - accuracy: 0.7133 - val_loss: 0.3219 - val_accuracy: 0.8668\n",
      "Epoch 2/8\n",
      "56/56 [==============================] - 11s 192ms/step - loss: 0.2812 - accuracy: 0.8843 - val_loss: 0.2753 - val_accuracy: 0.8884\n",
      "Epoch 3/8\n",
      "56/56 [==============================] - 11s 194ms/step - loss: 0.2364 - accuracy: 0.9022 - val_loss: 0.2933 - val_accuracy: 0.8805\n",
      "Epoch 4/8\n",
      "56/56 [==============================] - 11s 194ms/step - loss: 0.2264 - accuracy: 0.9050 - val_loss: 0.2326 - val_accuracy: 0.9094\n",
      "Epoch 5/8\n",
      "56/56 [==============================] - 11s 193ms/step - loss: 0.1693 - accuracy: 0.9334 - val_loss: 0.2188 - val_accuracy: 0.9160\n",
      "Epoch 6/8\n",
      "56/56 [==============================] - 11s 195ms/step - loss: 0.1404 - accuracy: 0.9471 - val_loss: 0.2747 - val_accuracy: 0.9055\n",
      "Epoch 7/8\n",
      "56/56 [==============================] - 11s 193ms/step - loss: 0.2111 - accuracy: 0.9207 - val_loss: 0.2187 - val_accuracy: 0.9191\n",
      "Epoch 8/8\n",
      "56/56 [==============================] - 11s 193ms/step - loss: 0.1151 - accuracy: 0.9570 - val_loss: 0.2204 - val_accuracy: 0.9287\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JszShl5AhRhe",
    "outputId": "02262f6e-5dc3-46ef-9eeb-eed04375a1bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.9288077681550149\n",
      "F1 score is 0.9287336683036287\n",
      "Acuracy is  0.9287336740488359\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "\n",
    "pred = model2.predict_classes(X_test)\n",
    "auc_score = roc_auc_score(y_test, pred)\n",
    "F1_score = f1_score(y_test, pred, average='macro')\n",
    "accuracy_score = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"AUC score is \", auc_score)\n",
    "print(\"F1 score is\", F1_score)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgL039oe3stV"
   },
   "source": [
    "##CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0_MJDmA3u3y"
   },
   "outputs": [],
   "source": [
    "def cnn_net1():\n",
    "  model = Sequential()\n",
    "\n",
    "  #Non-trainable embeddidng layer\n",
    "  model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "  \n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Conv1D(filters=128, kernel_size=4, activation='relu'))\n",
    "  model.add(GlobalMaxPooling1D())\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(units = 250 , activation = 'relu'))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "def get_pred_output(text_to_check):\n",
    "  sequences = tokenizer.texts_to_sequences([text_to_check])\n",
    "  data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "  predicted_val = model.predict_classes(data)\n",
    "#     predicted_val = model.predict(data)    \n",
    "#     if predicted_val.max() > 0.7:\n",
    "#         output = 1\n",
    "#     else:\n",
    "#         output = 0\n",
    "  return predicted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ll4Fc5C_4SA1",
    "outputId": "e512af29-e2fd-40d6-9ac9-e50382d85b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 300)          5085600   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 497, 128)          153728    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 250)               32250     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 5,271,829\n",
      "Trainable params: 186,229\n",
      "Non-trainable params: 5,085,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train a 1D convnet with global maxpooling\n",
    "model_1 = cnn_net1()\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 8\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vaR3CsK5UHP",
    "outputId": "5ed00960-603d-4ba2-aa08-a8d10a49db09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "56/56 [==============================] - 7s 109ms/step - loss: 0.6157 - accuracy: 0.6508 - val_loss: 0.3341 - val_accuracy: 0.8538\n",
      "Epoch 2/8\n",
      "56/56 [==============================] - 6s 102ms/step - loss: 0.3228 - accuracy: 0.8625 - val_loss: 0.2799 - val_accuracy: 0.8830\n",
      "Epoch 3/8\n",
      "56/56 [==============================] - 6s 101ms/step - loss: 0.2590 - accuracy: 0.8951 - val_loss: 0.2466 - val_accuracy: 0.8995\n",
      "Epoch 4/8\n",
      "56/56 [==============================] - 6s 101ms/step - loss: 0.2058 - accuracy: 0.9150 - val_loss: 0.2297 - val_accuracy: 0.9111\n",
      "Epoch 5/8\n",
      "56/56 [==============================] - 6s 101ms/step - loss: 0.1754 - accuracy: 0.9294 - val_loss: 0.2325 - val_accuracy: 0.9120\n",
      "Epoch 6/8\n",
      "56/56 [==============================] - 6s 101ms/step - loss: 0.1472 - accuracy: 0.9423 - val_loss: 0.2172 - val_accuracy: 0.9196\n",
      "Epoch 7/8\n",
      "56/56 [==============================] - 6s 101ms/step - loss: 0.1125 - accuracy: 0.9583 - val_loss: 0.2273 - val_accuracy: 0.9216\n",
      "Epoch 8/8\n",
      "56/56 [==============================] - 6s 101ms/step - loss: 0.0964 - accuracy: 0.9637 - val_loss: 0.2203 - val_accuracy: 0.9182\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(X_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnq8MHyH5Zc5",
    "outputId": "d5fa46a8-27e2-418d-ecf6-db93f0100ee8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.9182266883595385\n",
      "F1 score is 0.9182223460573977\n",
      "Acuracy is  0.9182282793867121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = model_1.predict_classes(X_test)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred)\n",
    "print(\"AUC score is \", auc_score)\n",
    "\n",
    "F1_score = f1_score(y_test, pred, average='macro')\n",
    "print(\"F1 score is\", F1_score)\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, pred)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "VShdUe1m_G56",
    "CheemUFh_G5-",
    "07_mwkKb_G6I"
   ],
   "name": "fake_real_news_training_8800-wordvec-gloVe.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
